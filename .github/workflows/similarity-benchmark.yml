name: LLaMA Similarity Benchmark

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  run-bpmn-comparison:
    runs-on: ubuntu-latest
    env:
      OLLAMA_MODEL: tinyllama
      OLLAMA_DEVICE: cpu
      OUTPUT_DIR: results

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y curl git build-essential

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ollama

      - name: Create prompt file from Secret
        run: echo "${{ secrets.BPMN_PROMPT }}" > prompt.txt
        # QUI SI PRENDE IL PROMPT DAL SECRET BPMN_PROMPT

      - name: Write Python script
        run: |
          cat > compare_bpmn.py <<'PY'
import os
import xml.etree.ElementTree as ET
from itertools import combinations
import csv
import re
import time

try:
    import ollama
except Exception as ex:
    print('Errore import ollama:', ex)
    raise

os.environ.setdefault('OLLAMA_DEVICE', os.environ.get('OLLAMA_DEVICE', 'cpu'))
OLLAMA_MODEL = os.environ.get('OLLAMA_MODEL', 'tinyllama')
OUTPUT_DIR = os.environ.get('OUTPUT_DIR', 'results')

# Legge il prompt dal file creato dal secret
with open('prompt.txt', 'r', encoding='utf-8') as f:
    prompt = f.read()

# TODO: definisci qui tutte le funzioni del tuo script compare_bpmn.py
print('Script scritto correttamente')
PY

      - name: Ensure output dir exists
        run: mkdir -p ${{ env.OUTPUT_DIR }}

      - name: Run Python script
        run: python compare_bpmn.py

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: bpmn-similarity-results
          path: ${{ env.OUTPUT_DIR }}

